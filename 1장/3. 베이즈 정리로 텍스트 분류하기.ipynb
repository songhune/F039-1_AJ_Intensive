{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How To Use NLP# 텍스트 분석과 챗봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 베이즈 정리로 텍스트 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Text Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "   def fit(text, spam):\n",
    "        \"\"\" 텍스트 학습 \"\"\"\n",
    "        word_list = text.split()\n",
    "        for word in word_list:\n",
    "            word_count(word, spam)\n",
    "        spam_calc(spam)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "   def word_count(word, spam):\n",
    "        # 단어를 스팸 카테고리에 추가하기\n",
    "        if not spam in word_dict:\n",
    "            word_dict[spam] = {}\n",
    "        if not word in word_dict[spam]:\n",
    "            word_dict[spam][word] = 0\n",
    "        word_dict[spam][word] += 1\n",
    "        words.add(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "     def spam_calc(spam):\n",
    "        if not spam in spam_dict:\n",
    "            spam_dict[spam] = 0\n",
    "        spam_dict[spam] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=set()\n",
    "word_dict={}\n",
    "spam_dict={}\n",
    "\n",
    "fit('파격세일 - 오늘까지만 30% 할인', 'spam')\n",
    "fit(\"쿠폰 선물 & 무료 배송\", \"spam\")\n",
    "fit(\"오늘 일정 확인\", \"ham\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spam': {'파격세일': 1, '-': 1, '오늘까지만': 1, '30%': 1, '할인': 1, '쿠폰': 1, '선물': 1, '&': 1, '무료': 1, '배송': 1}, 'ham': {'오늘': 1, '일정': 1, '확인': 1}}\n",
      "{'spam': 2, 'ham': 1}\n"
     ]
    }
   ],
   "source": [
    "print(word_dict)\n",
    "print(spam_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, sys\n",
    "from konlpy.tag import Twitter\n",
    "class BayesianClassifier:\n",
    "\n",
    "    \"\"\" 베이지안 분류기\n",
    "        세부기능 1 / 2로 구분\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.words = set() # 출현   단어 기록\n",
    "        self.word_dict = {} # 단어 출현 횟수 기록 , dict형\n",
    "        self.spam_dict = {} # 스팸 출현 횟수 기록 , dict형\n",
    "        \n",
    "   # 세부기능 1: 텍스트 전체서 스팸 계산하기\n",
    "    def fit(self, text, spam):\n",
    "        \"\"\" 텍스트 학습 \"\"\"\n",
    "        word_list = self.split(text)\n",
    "        for word in word_list:\n",
    "            self.word_count(word, spam)\n",
    "        self.spam_calc(spam)        \n",
    "    \n",
    "    # 세부기능 1: 형태소 분석하기 \n",
    "    def split(self, text):\n",
    "        results = []\n",
    "        twitter = Twitter()\n",
    "        # 단어의 기본형 사용\n",
    "        postag = twitter.pos(text, norm=True, stem=True)\n",
    "        for word in postag:\n",
    "            # 어미/조사/구두점 등은 대상에서 제외 \n",
    "            if not word[1] in [\"Josa\", \"Eomi\", \"Punctuation\"]:\n",
    "                results.append(word[0])\n",
    "        return results\n",
    "    \n",
    "    # 세부기능 1: 단어와 스팸의 출현 횟수 추가 단어 추가\n",
    "    def word_count(self, word, spam):\n",
    "        # 단어를 스팸 카테고리에 추가하기\n",
    "        if not spam in self.word_dict: #초기화 1. word_dict에 spam카테고리가 없으면 만들어준다\n",
    "            self.word_dict[spam] = {}\n",
    "        if not word in self.word_dict[spam]: #초기화 2. spam카테고리에 아무것도 없으면 단어 개수를 넣고 단어를 추가한다. \n",
    "            self.word_dict[spam][word] = 0\n",
    "        self.word_dict[spam][word] += 1 #스팸 단어 카운트 증가\n",
    "        self.words.add(word) #단어 추가\n",
    "    \n",
    "    # 세부기능 1: 스팸 계산하기\n",
    "    def spam_calc(self, spam):\n",
    "        if not spam in self.spam_dict:\n",
    "            self.spam_dict[spam] = 0\n",
    "        self.spam_dict[spam] += 1\n",
    "        \n",
    "\n",
    "   # 세부기능 2: 예측하기 \n",
    "    def predict(self, text):\n",
    "        spam_select = None\n",
    "        max_score = -sys.maxsize \n",
    "        \n",
    "        words = self.split(text)\n",
    "        score_list = []\n",
    "        for spam in self.spam_dict.keys():\n",
    "            score = self.score(words, spam)\n",
    "            score_list.append((spam, score)) \n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                spam_select = spam\n",
    "        return spam_select, score_list\n",
    "    \n",
    "    # P(B)*P(A|B)= 단어 리스트에 점수 매기기\n",
    "    def score(self, words, spam):\n",
    "        score = math.log(self.spam_prob(spam)) #Tips. 확률이므로 log값을 사용해 downflow예방\n",
    "        for word in words:\n",
    "            score += math.log(self.word_prob(word, spam)) \n",
    "        return score\n",
    "        \n",
    "    # 스팸 내부의 단어 출현 횟수 구하기\n",
    "    def get_word_count(self, word, spam):\n",
    "        if word in self.word_dict[spam]:\n",
    "            return self.word_dict[spam][word]\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    # P(B)= 전체 문서에서 해당 카테고리로 분류될 확률 계산\n",
    "    def spam_prob(self, spam):\n",
    "        sum_spam = sum(self.spam_dict.values()) #전체 문장의 수\n",
    "        spam_v = self.spam_dict[spam] #새로 들어가는 문장의 class\n",
    "        return spam_v / sum_spam\n",
    "        \n",
    "    # P(A|B)= 스팸 내부의 단어 출현율 계산\n",
    "    def word_prob(self, word, spam):\n",
    "        n = self.get_word_count(word, spam) + 1 #학습 사전에 없는 단어가 나오면 spam확률이 0이 되므로\n",
    "        d = sum(self.word_dict[spam].values()) + len(self.words)\n",
    "        return n / d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Baysian Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과 = 광고\n",
      "[('광고', -19.00139285840871), ('중요', -20.449365773467083)]\n"
     ]
    }
   ],
   "source": [
    "bc = BayesianClassifier()\n",
    "# 텍스트 학습\n",
    "bc.fit(\"파격 세일 - 오늘까지만 30% 할인\", \"광고\")\n",
    "bc.fit(\"쿠폰 선물 & 무료 배송\", \"광고\")\n",
    "bc.fit(\"현데계 백화점 세일\", \"광고\")\n",
    "bc.fit(\"봄과 함께 찾아온 따뜻한 신제품 소식\", \"광고\")\n",
    "bc.fit(\"인기 제품 기간 한정 세일\", \"광고\")\n",
    "bc.fit(\"오늘 일정 확인\", \"중요\")\n",
    "bc.fit(\"프로젝트 진행 상황 보고\",\"중요\")\n",
    "bc.fit(\"계약 잘 부탁드립니다\",\"중요\")\n",
    "bc.fit(\"회의 일정이 등록되었습니다.\",\"중요\")\n",
    "bc.fit(\"오늘 일정이 없습니다.\",\"중요\")\n",
    "# 예측\n",
    "pre, scorelist = bc.predict(\"재고 정리 할인, 무료 배송\")\n",
    "print(\"결과 =\", pre)\n",
    "print(scorelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summerize\n",
    "**베이즈 정리를 활용해 스팸 필터링 등 classification이 가능하다**  \n",
    "**단어/카테고리 정리만 가지고 classification이 가능하다**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
